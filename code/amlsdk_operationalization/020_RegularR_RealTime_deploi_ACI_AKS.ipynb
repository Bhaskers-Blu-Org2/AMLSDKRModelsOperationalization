{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copyright (C) Microsoft Corporation.    \n",
    "  \n",
    "# Deploy regular ML R model in ACI and AKS\n",
    "  \n",
    "#### Authors\n",
    "\n",
    "* **George Iordanescu** - [Microsoft AI CAT](https://github.com/Azure/o16nRegularMLRmodelsUsingAzurek8s)\n",
    "\n",
    "See also the list of [contributors](https://github.com/Azure/o16nRegularMLRmodelsUsingAzurek8s/contributors) who participated in this project.  \n",
    "  \n",
    "* Use the user provided R model and R scoring script embedded in the containerized Python operationalization (o16n) script to deloy R model at scale using [Azure Kubernetes Service](https://docs.microsoft.com/en-us/azure/aks/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow multiple displays per cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/opt/conda/envs/aml-sdk-conda-env/lib/python3.6/site-packages/azureml/__init__.py'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Linux-4.9.125-linuxkit-x86_64-with-debian-9.5'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/workspace/code/amlsdk_operationalization'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/opt/conda/envs/aml-sdk-conda-env/lib/python3.6/site-packages/azureml/__init__.py'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check core SDK version number, os info and current wd\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)\n",
    "\n",
    "#azure ml files location\n",
    "azureml.__file__\n",
    "\n",
    "import platform\n",
    "platform.platform()\n",
    "\n",
    "import os\n",
    "os.getcwd()\n",
    "\n",
    "# Show SDK files location\n",
    "azureml.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import utility functions like project config params\n",
    "\n",
    "import sys, os\n",
    "\n",
    "def add_path_to_sys_path(path_to_append):\n",
    "    if not (any(path_to_append in paths for paths in sys.path)):\n",
    "        sys.path.append(path_to_append)\n",
    "\n",
    "auxiliary_files_dir = os.path.join(*(['.', 'src']))\n",
    "\n",
    "paths_to_append = [os.path.join(os.getcwd(), auxiliary_files_dir)]\n",
    "[add_path_to_sys_path(crt_path) for crt_path in paths_to_append]\n",
    "\n",
    "import o16n_regular_ML_R_models_utils\n",
    "prj_consts = o16n_regular_ML_R_models_utils.o16n_regular_ML_R_models_consts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dotenv is used to hide sensitive info, like Azure subscription name/ID. The serialized info should have been already manually input once, in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../../not_shared/general.env'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "dotenv_file_path = os.path.join(*(prj_consts.DOTENV_FILE_PATH))\n",
    "\n",
    "#show .env file path\n",
    "dotenv_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set true all below flags when deployng for the first time. \n",
    "Switch to false as needed after that, to avoid multiple artifacts (registered models, ACR-ed images, k8s clusters and so on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_model = True\n",
    "create_AML_Image= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "%dotenv $dotenv_file_path\n",
    "\n",
    "import os\n",
    "#use .env file created in previous notebook to access parameters:\n",
    "subscription_id = os.getenv('SUBSCRIPTION_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define some variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../not_shared'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define project params\n",
    "prj_consts = o16n_regular_ML_R_models_utils.o16n_regular_ML_R_models_consts()\n",
    "\n",
    "\n",
    "r_model_AML_name = prj_consts.R_MODEL_AML_NAME\n",
    "r_model_file_name = prj_consts.R_MODEL_FILE_NAME\n",
    "conda_dependencies_filename = prj_consts.R_MODEL_CONDA_DEPENDENCIES_FILE_NAME\n",
    "score_script_filename = prj_consts.SCORE_SCRIPT_FILE_NAME\n",
    "experiment_dir = os.path.join(*(prj_consts.AML_EXPERIMENT_DIR))\n",
    "o16n_docker_image_name = prj_consts.o16n_DOCKER_IMAGE_NAME\n",
    "\n",
    "workspace_config_dir = os.path.join(*(prj_consts.AML_WORKSPACE_CONFIG_DIR))\n",
    "workspace_config_dir\n",
    "workspace_config_file = prj_consts.AML_WORKSPACE_CONFIG_FILE_NAME\n",
    "\n",
    "o16n_info_env_file = 'o16ninfo.env'\n",
    "\n",
    "# check if we have the right elements for o16n\n",
    "\n",
    "os.path.isfile( os.path.join(os.getcwd(), os.path.join(experiment_dir, conda_dependencies_filename)))\n",
    "os.path.isfile( os.path.join(os.getcwd(), os.path.join(experiment_dir, score_script_filename)))\n",
    "\n",
    "R_artifacts_dir = os.path.join(os.getcwd(), os.path.join(*(prj_consts.R_MODEL_DIR)))\n",
    "os.path.isfile(os.path.join(R_artifacts_dir, r_model_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Workspace\n",
    "\n",
    "Initialize a workspace object configuration persisted in previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /workspace/not_shared/aml_config/aml_ws_config.json\n",
      "ghiordanregularrrealtimews\n",
      "ghiordanRo16n1rsg02\n",
      "eastus2\n",
      "e\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config(path=os.path.join(os.getcwd(), \n",
    "                                             os.path.join(*([workspace_config_dir, 'aml_config', workspace_config_file]))))\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id[0], sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can register a model, and choose one of the registered ones for deployment. This step can be skipped since there should already be a model registered from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model trained_r_model\n",
      "trained_r_model\tmy R model\t2\t{'language': 'R', 'type': 'TC_kSVM'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "# register_model = True\n",
    "if register_model:\n",
    "    model = Model.register(model_path = os.path.join(R_artifacts_dir, r_model_file_name),\n",
    "                           model_name = r_model_AML_name,\n",
    "                           tags = {'language': 'R', 'type': 'TC_kSVM'},\n",
    "                           description = 'my R model',\n",
    "                           workspace = ws)\n",
    "    \n",
    "    print(model.name, model.description, model.version, model.tags, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can explore the registered models within your workspace and query by tag. Models are versioned. If you call the register_model command many times with same model name, you will get multiple versions of the model with increasing version numbers.   \n",
    "For demo purposes, we choose v1 as the model used for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: trained_r_model \tVersion: 2 \tDescription: my R model {'language': 'R', 'type': 'TC_kSVM'}\n",
      "Name: trained_r_model \tVersion: 1 \tDescription: my R model {'language': 'R', 'type': 'TC_kSVM'}\n",
      "trained_r_model\tmy R model\t1\n"
     ]
    }
   ],
   "source": [
    "best_r_model = None\n",
    "\n",
    "for m in Model.list(ws, tags={'type': 'TC_kSVM'}):\n",
    "# for m in r_models:\n",
    "    print(\"Name:\", m.name,\"\\tVersion:\", m.version, \"\\tDescription:\", m.description, m.tags)\n",
    "    if ((m.name==r_model_AML_name) and (m.version==1) and (m.description=='my R model')):\n",
    "        best_r_model = m\n",
    "\n",
    "print(best_r_model.name, best_r_model.description, best_r_model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print content of scoring script (o16n pyth0n script that embeds the user provided R scoring script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "import pickle\r\n",
      "import json\r\n",
      "from azureml.core.model import Model\r\n",
      "import rpy2\r\n",
      "import rpy2.robjects as robjects\r\n",
      "import timeit\r\n",
      "import logging\r\n",
      "\r\n",
      "R_MODEL_AML_NAME = 'trained_r_model'\r\n",
      "\r\n",
      "\r\n",
      "def init():\r\n",
      "    from rpy2.rinterface import R_VERSION_BUILD\r\n",
      "    print('rpy2 version {};  R version {}'.format(rpy2.__version__, R_VERSION_BUILD))\r\n",
      "    \r\n",
      "    print('R model AML name: {}'.format(Model.get_model_path(model_name='trained_r_model')))\r\n",
      "    \r\n",
      "    global model\r\n",
      "    # note here \"best_model\" is the name of the model registered under the workspace\r\n",
      "    # this call should return the path to the model.pkl file on the local disk.\r\n",
      "    model_path = Model.get_model_path(model_name =  'trained_r_model')\r\n",
      "    # deserialize the model file back into a sklearn model\r\n",
      "    robjects.globalenv['model_path'] = model_path    \r\n",
      "    # model_path = robjects.StrVector( 'ksvm_model.rds')\r\n",
      "    robjects.r('''\r\n",
      "            format_proc_time <- function(proc_time_diff){\r\n",
      "                \r\n",
      "                as.data.frame(t(as.matrix(format(round(proc_time_diff*1000, 2), nsmall = 2))))[, \r\n",
      "                                                            c('user.self', 'sys.self', 'elapsed')]\r\n",
      "            }\r\n",
      "            library(kernlab)\r\n",
      "            library(jsonlite)\r\n",
      "            svm_model = readRDS({model_path})\r\n",
      "            ''')\r\n",
      "    print('AML o16n init() function: SVM model loaded.')\r\n",
      "\r\n",
      "# note you can pass in multiple rows for scoring\r\n",
      "def run(aml_jsoned_data):\r\n",
      "    logger = logging.getLogger(\"AML_o16n_run_function\")\r\n",
      "#     print('Entering run() function')\r\n",
      "    try:\r\n",
      "        start_time = timeit.default_timer()\r\n",
      "#         data = json.loads(raw_data)['data']\r\n",
      "        data = json.loads(aml_jsoned_data)['data']\r\n",
      "        robjects.globalenv['r_data_to_score'] = data  \r\n",
      "        python_to_R_time = timeit.default_timer()\r\n",
      "        r_messages = robjects.r('''\r\n",
      "                start_time_r = proc.time()\r\n",
      "                \r\n",
      "                r_data_to_score=jsonlite::fromJSON(r_data_to_score[[1]])\r\n",
      "                json_to_df_time_r = proc.time()\r\n",
      "                \r\n",
      "                scores = kernlab::predict(svm_model,r_data_to_score, type = \"p\")\r\n",
      "                end_time_r = proc.time()\r\n",
      "                \r\n",
      "                # report total time and json to df time\r\n",
      "                time_df = rbind(format_proc_time(end_time_r - start_time_r),\r\n",
      "                                format_proc_time(json_to_df_time_r - start_time_r))\r\n",
      "                rownames(time_df)=c('all_r_time','json_to_df_time')    \r\n",
      "                \r\n",
      "                # combine scores and time dataframes in a list\r\n",
      "                returned_list = list(as.data.frame(scores),time_df)\r\n",
      "                names(returned_list)=c('r_scores', 'r_times')\r\n",
      "                \r\n",
      "                scores = jsonlite::toJSON(returned_list)\r\n",
      "                #print('Exiting R.')\r\n",
      "                ''')\r\n",
      "        before_R_to_python_time = timeit.default_timer()\r\n",
      "        \r\n",
      "        jsoned_scores = (robjects.r['scores'])[0]\r\n",
      "        end_time = timeit.default_timer()\r\n",
      "        \r\n",
      "#         logger.info(\"Predictions: {0}\".format(jsoned_scores))\r\n",
      "#         print('Exiting run() function')\r\n",
      "        return json.dumps({'python_scores': jsoned_scores, \r\n",
      "                           'python_times': json.dumps(\r\n",
      "                               {'all_p_time':'{} ms'.format(round((end_time-start_time)*1000, 2)),\r\n",
      "                                           'python_to_R_time':'{} ms'.format(round((python_to_R_time-start_time)*1000, 2)),\r\n",
      "                                           'R_to_python_time':'{} ms'.format(round((end_time-before_R_to_python_time)*1000, 2))}\r\n",
      "                           )\r\n",
      "                          })\r\n",
      "\r\n",
      "    except Exception as e:\r\n",
      "        result = str(e)\r\n",
      "        return json.dumps({\"AML o16n run() function: error\": result})\r\n",
      "    \r\n",
      "def main():\r\n",
      "    import numpy as np\r\n",
      "    import pandas as pd\r\n",
      "    \r\n",
      "    n_samples = 100\r\n",
      "\r\n",
      "    raw_data = 2 * np.random.random_sample((n_samples, 2)) - 1\r\n",
      "    aml_jsoned_data =  json.dumps({'data': json.dumps(raw_data.tolist())})\r\n",
      "  \r\n",
      "    init()\r\n",
      "    response = run(aml_jsoned_data)\r\n",
      "#     print(json.loads(response))\r\n",
      "#     print( json.loads(json.loads(response)['python_scores']) )\r\n",
      "    \r\n",
      "    print( pd.DataFrame.from_records(json.loads(json.loads(response)['python_scores'])['r_scores']) )\r\n",
      "    print( pd.DataFrame.from_records(json.loads(json.loads(response)['python_scores'])['r_times']) )\r\n",
      "    for k, v in json.loads(json.loads(response)['python_times']).items():\r\n",
      "        print(v, k)\r\n",
      "\r\n",
      "    print('Exited main() function')\r\n",
      "    \r\n",
      "if __name__== \"__main__\":\r\n",
      "    main()\r\n",
      "    \r\n"
     ]
    }
   ],
   "source": [
    "!cat {os.path.join(os.getcwd(), os.path.join(experiment_dir, score_script_filename))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print content of conda_dependencies yml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\r",
      "\r\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\r",
      "\r\n",
      "\r\n",
      "# Details about the Conda environment file format:\r",
      "\r\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\r",
      "\r\n",
      "\r\n",
      "name: project_environment\r\n",
      "dependencies:\r\n",
      "  # The python interpreter version.\r",
      "\r\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\r",
      "\r\n",
      "- python=3.7.0\r\n",
      "\r\n",
      "- pip:\r\n",
      "    # Required packages for AzureML execution, history, and data preparation.\r",
      "\r\n",
      "  - azureml-defaults\r\n",
      "- r-base\r\n",
      "- r-proc\r\n",
      "- r-jsonlite\r\n",
      "- r-kernlab\r\n",
      "- rpy2\r\n",
      "- pandas\r\n",
      "- gfortran_linux-64\r\n",
      "channels:\r\n",
      "- r\r\n",
      "- conda-forge\r\n",
      "- anaconda\r\n"
     ]
    }
   ],
   "source": [
    "! cat {os.path.join(os.getcwd(), os.path.join(*[experiment_dir, conda_dependencies_filename]))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create o16n image, using registered model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running..........................................................................................................................\n",
      "SucceededImage creation operation finished for image regml-r-realtime-image001:1, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.image import Image, ContainerImage\n",
    "\n",
    "# create_AML_Image= False\n",
    "\n",
    "if create_AML_Image:\n",
    "    crt_dir = os.getcwd()\n",
    "    os.chdir(os.path.join(os.getcwd(), os.path.join(*[experiment_dir])))\n",
    "\n",
    "\n",
    "    image_config = ContainerImage.image_configuration(runtime= \"python\",\n",
    "                                     execution_script=score_script_filename,\n",
    "                                     conda_file=conda_dependencies_filename,\n",
    "                                     tags = {'area': \"R models o16n\", 'type': \"regular ML\"},\n",
    "                                     description = \"Image with kSVM R model o16n-ed via rpy2\")\n",
    "\n",
    "    image = Image.create(name = o16n_docker_image_name,\n",
    "                         # this is the model object \n",
    "                         models = [best_r_model],\n",
    "                         image_config = image_config, \n",
    "                         workspace = ws)\n",
    "\n",
    "    image.wait_for_creation(show_output = True)\n",
    "    os.chdir(crt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !az ml image list -g {ws.resource_group} -w {ws.name} --query \"[].imageLocation\" -o table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regml-r-realtime-image001(v.1 [Succeeded]) stored at ghiordanacrrdtinxhv.azurecr.io/regml-r-realtime-image001:1 with build log https://ghiordanstorageapxaeimu.blob.core.windows.net/azureml/ImageLogs/0c049e83-deed-4707-9f21-a4e50466a2c8/build.log?sv=2017-04-17&sr=b&sig=gIjm8cLh81VXbOYxwIyPJlrnz%2Bc0rZIMtM3%2FQ8%2FNe%2FY%3D&st=2019-03-08T18%3A47%3A52Z&se=2019-04-07T18%3A52%3A52Z&sp=rl\n",
      "image_to_deploy:\n",
      "regml-r-realtime-image001\t1\tghiordanacrrdtinxhv.azurecr.io/regml-r-realtime-image001:1\n"
     ]
    }
   ],
   "source": [
    "image_to_deploy= None\n",
    "for i in Image.list(workspace = ws,tags = {'area': \"R models o16n\"}):\n",
    "    print('{}(v.{} [{}]) stored at {} with build log {}'.format(i.name, \n",
    "                                                                i.version, \n",
    "                                                                i.creation_state, \n",
    "                                                                i.image_location, \n",
    "                                                                i.image_build_log_uri))\n",
    "    if ((i.name==o16n_docker_image_name) and (i.version==1)):\n",
    "        image_to_deploy = i\n",
    "\n",
    "print('image_to_deploy:')\n",
    "print(image_to_deploy.name, image_to_deploy.version, image_to_deploy.image_location, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy image as web service on Azure Container Instance\n",
    "\n",
    "Note that the service creation can take few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                               memory_gb = 1, \n",
    "                                               tags = {'area': \"R models o16n\"}, \n",
    "                                               description = 'demo R SVM model in AML ACI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all web services in the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name, state, created_time, compute_type, description, scoring_uri, scoring_uri, image_id, image\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import Webservice \n",
    "\n",
    "print('name, state, created_time, compute_type, description, scoring_uri, scoring_uri, image_id, image')\n",
    "for crt_webservice in Webservice.list(workspace = ws):\n",
    "    print('{}, {}, {}, {}, {}, {}, {}, {}'.format(crt_webservice.name,\n",
    "                                                  crt_webservice.state,\n",
    "                                                  crt_webservice.created_time,\n",
    "                                                  crt_webservice.compute_type,\n",
    "                                                  crt_webservice.description,\n",
    "                                                  crt_webservice.scoring_uri,\n",
    "                                                  crt_webservice.image_id,\n",
    "                                                  crt_webservice.image.name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r-svm-aci-service-01\n",
      "Creating service\n",
      "Running................................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "from azureml.exceptions import WebserviceException\n",
    "\n",
    "aci_service_name = 'r-svm-aci-service-01'\n",
    "print(aci_service_name)\n",
    "\n",
    "try:\n",
    "    aci_service = Webservice.deploy_from_image(deployment_config = aciconfig,\n",
    "                                           image = image_to_deploy,\n",
    "                                           name = aci_service_name,\n",
    "                                           workspace = ws)\n",
    "    aci_service.wait_for_deployment(True)\n",
    "    print(aci_service.state)\n",
    "except WebserviceException:\n",
    "    print('WebserviceException: There is already a service with name {} found in workspace {}. Will use it, and not create another one!'\\\n",
    "          .format(aci_service_name, ws.name))\n",
    "    aci_service = Webservice(workspace = ws, name = aci_service_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test web service\n",
    "Call the web service with some dummy input data to get a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"data\": \"[[-0.5420484953083147, 0.11608820222055583], [-0.8859547984134335, 0.5742562341106612], [0.9432759636624082, -0.5863462843014455]]\"}'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "raw_data = 2 * np.random.random_sample((3, 2)) - 1\n",
    "json.dumps({'data': json.dumps(raw_data.tolist())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              _row elapsed sys.self user.self\n",
      "0       all_r_time  231.00    16.00    228.00\n",
      "1  json_to_df_time   11.00     0.00     11.00\n",
      "294.83 ms all_p_time\n",
      "0.19 ms python_to_R_time\n",
      "0.06 ms R_to_python_time\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "n_samples = 1000\n",
    "\n",
    "raw_data = 2 * np.random.random_sample((n_samples, 2)) - 1\n",
    "if n_samples<10:\n",
    "    raw_data\n",
    "\n",
    "aml_jsoned_data =  json.dumps({'data': json.dumps(raw_data.tolist())})\n",
    "response = aci_service.run(input_data = aml_jsoned_data)\n",
    "\n",
    "if n_samples<10:\n",
    "    print( pd.DataFrame.from_records(json.loads(json.loads(response)['python_scores'])['r_scores']) )\n",
    "\n",
    "print( pd.DataFrame.from_records(json.loads(json.loads(response)['python_scores'])['r_times']) )\n",
    "for k, v in json.loads(json.loads(response)['python_times']).items():\n",
    "    print(v, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_row</th>\n",
       "      <th>elapsed</th>\n",
       "      <th>sys.self</th>\n",
       "      <th>user.self</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all_r_time</td>\n",
       "      <td>231.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>228.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>json_to_df_time</td>\n",
       "      <td>11.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              _row elapsed sys.self user.self\n",
       "0       all_r_time  231.00    16.00    228.00\n",
       "1  json_to_df_time   11.00     0.00     11.00"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'231.00'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'all_p_time': '294.83 ms',\n",
       " 'python_to_R_time': '0.19 ms',\n",
       " 'R_to_python_time': '0.06 ms'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'294.83 ms'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpy overhead summary \t \n",
      "r_processing time \t 231 ms\n",
      "python_processing time \t 295 ms\n",
      "rpy overhead \t 27.63 %\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame.from_records(json.loads(json.loads(response)['python_scores'])['r_times'])\n",
    "pd.DataFrame.from_records(json.loads(json.loads(response)['python_scores'])['r_times']).iloc[0,1]\n",
    "\n",
    "json.loads(json.loads(response)['python_times'])\n",
    "json.loads(json.loads(response)['python_times'])['all_p_time']\n",
    "\n",
    "def rpy_times_report(r_times_dataframe, python_times_dict):\n",
    "    python_time_number, python_time_unit = python_times_dict['all_p_time'].split()\n",
    "    r_time_number = r_times_dataframe.iloc[0,1]\n",
    "\n",
    "    for crt_key, crt_value in \\\n",
    "    {'rpy overhead summary':'',\n",
    "     'r_processing time':'{} ms'.format(round(float(r_time_number)), 2),\n",
    "     'python_processing time':'{} ms'.format(round(float(python_time_number)), 2),\n",
    "     'rpy overhead':'{} %'.format(round(((float(python_time_number)-float(r_time_number))/float(r_time_number))*100, 2))}.items():\n",
    "        print(crt_key, '\\t',crt_value)  \n",
    "\n",
    "rpy_times_report(pd.DataFrame.from_records(json.loads(json.loads(response)['python_scores'])['r_times']),\n",
    "                json.loads(json.loads(response)['python_times']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "time_test_results = list()\n",
    "time_test_data_sizes = (1e1, 1e1, 1e3, 1e3, 1e5, 1e5, 3e5, 3e5)\n",
    "time_test_data_sizes = (1e1, 1e1, 1e3, 1e3, 1e5, 1e5)\n",
    "\n",
    "def test_service(data_size, scoring_service):\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    raw_data = 2 * np.random.random_sample((data_size, 2)) - 1\n",
    "    aml_jsoned_data =  json.dumps({'data': json.dumps(raw_data.tolist())})\n",
    "    print('\\n data_size: {} rows, jsoned data is {} chars long'.format(data_size, len(aml_jsoned_data)))\n",
    "    \n",
    "    start_service_time = timeit.default_timer()\n",
    "    response = scoring_service.run(input_data = aml_jsoned_data)\n",
    "    return_service_time = timeit.default_timer()\n",
    "    \n",
    "    print( pd.DataFrame.from_records(json.loads(json.loads(response)['python_scores'])['r_times']) )\n",
    "    \n",
    "    for k, v in json.loads(json.loads(response)['python_times']).items():\n",
    "        print(v, k)\n",
    "    \n",
    "    end_time = timeit.default_timer()\n",
    "    for crt_key, crt_value in \\\n",
    "    {'e2e_time':'{} ms'.format(round((end_time-start_time)*1000, 2)),\n",
    "          'service_time':'{} ms'.format(round((return_service_time-start_service_time)*1000, 2)),\n",
    "          'data_generation_time':'{} ms'.format(round((start_service_time-start_time)*1000, 2)),\n",
    "          'response_print_time':'{} ms'.format(round((end_time-return_service_time)*1000, 2))}.items():\n",
    "        print(crt_key, ': ',crt_value)\n",
    "    \n",
    "    rpy_times_report(pd.DataFrame.from_records(json.loads(json.loads(response)['python_scores'])['r_times']),\n",
    "                json.loads(json.loads(response)['python_times']))\n",
    "    \n",
    "# aci proper testing moved near aks testing, below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "\n",
    "o16n_info_env_file_name = os.path.join(os.getcwd(), os.path.join(*([workspace_config_dir,  o16n_info_env_file])))\n",
    "\n",
    "# with open(o16n_info_env_file_name, 'a+') as f:\n",
    "# #     print(o16n_info_env_file_name)\n",
    "#     pass\n",
    "\n",
    "# # with open(o16n_info_env_file_name, 'w+') as f:\n",
    "# #     f.write(\"aci_scoring_uri={}\\n\".format(aci_service.scoring_uri))\n",
    "# dotenv.set_key(o16n_info_env_file_name, 'aci_scoring_uri', aci_service.scoring_uri)    \n",
    "# # o16n_info_env_file_name\n",
    "# # !cat $o16n_info_env_file_name\n",
    "\n",
    "o16n_regular_ML_R_models_utils.set_dotenv_info(o16n_info_env_file_name, {'aci_scoring_uri':aci_service.scoring_uri})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://40.90.247.90:80/score'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv $o16n_info_env_file_name\n",
    "os.getenv('aci_scoring_uri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aci_service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provision the AKS Cluster\n",
    "This is a one time setup. You can reuse this cluster for multiple deployments after it has been created. If you delete the cluster or the resource group that contains it, then you would have to recreate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "# Use the default configuration (can also provide parameters to customize)\n",
    "prov_config = AksCompute.provisioning_configuration()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ghiordanXRgpuvm\n",
      "VirtualMachine\n",
      "None\n",
      "Succeeded\n"
     ]
    }
   ],
   "source": [
    "for crt_compute_target in ComputeTarget.list(workspace = ws):\n",
    "    print(crt_compute_target.name)\n",
    "#     print(crt_compute_target.cluster_resource_id)\n",
    "    print(crt_compute_target.type)\n",
    "    print(crt_compute_target.description)\n",
    "    print(crt_compute_target.get_status())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !az aks get-credentials -n r-aks-clst03f0d01421a14ff1 -g $project_new_rsg -a -f r-aks-clst03.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "aks_cluster_name = 'ro16n-aks-001'\n",
    "\n",
    "# Create the AKS cluster. Existing clusters will be reused\n",
    "aks_target = ComputeTarget.create(workspace = ws, \n",
    "                                  name = aks_cluster_name, \n",
    "                                  provisioning_configuration = prov_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating.................................................................................\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded\n",
      "None\n",
      "CPU times: user 1.59 s, sys: 210 ms, total: 1.8 s\n",
      "Wall time: 7min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "aks_cluster_name\n",
    "aks_target.wait_for_completion(show_output = True)\n",
    "print(aks_target.provisioning_state)\n",
    "print(aks_target.provisioning_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crt_aks_cluster_resource_id = '/subscriptions/[...]/resourcegroups/ghiordanchestXRAMLBAIT01rsg01/providers/Microsoft.ContainerService/managedClusters/ro16n-aks-0017cc666178'\n",
    "# dotenv_response = dotenv.set_key(o16n_info_env_file_name, 'aks_cluster_resource_id', crt_aks_cluster_resource_id)  \n",
    "# # dotenv_response\n",
    "# !cat $o16n_info_env_file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_id = aks_target.cluster_resource_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional step: Attach existing AKS cluster\n",
    "If you have existing AKS cluster in your Azure subscription, you can attach it to the Workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 9.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Use the default configuration (can also provide parameters to customize)\n",
    "\n",
    "attach_cluster = False\n",
    "if (attach_cluster):\n",
    "    # attach existing  cluster\n",
    "    \n",
    "    attach_config = AksCompute.attach_configuration(resource_id=resource_id)\n",
    "    aks_target = ComputeTarget.attach(workspace=ws, name=aks_cluster_name, attach_configuration=attach_config)\n",
    "    # Wait for the operation to complete\n",
    "    aks_target.wait_for_completion(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy web service to AKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the web service configuration (using default here)\n",
    "aks_config = AksWebservice.deploy_configuration()\n",
    "\n",
    "# aks_config = AksWebservice.deploy_configuration(\n",
    "#      autoscale_enabled=None, autoscale_min_replicas=None, \n",
    "#                                                 autoscale_max_replicas=None, autoscale_refresh_seconds=None, \n",
    "#                                                 autoscale_target_utilization=None, collect_model_data=None, \n",
    "#                                                 cpu_cores=None, memory_gb=None, enable_app_insights=None, \n",
    "#                                                 scoring_timeout_ms=None, replica_max_concurrent_requests=None, \n",
    "#                                                 num_replicas=None, primary_key=None, secondary_key=None, \n",
    "#                                                 tags=None, description=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating service\n",
      "Running...................\n",
      "SucceededAKS service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "CPU times: user 640 ms, sys: 40 ms, total: 680 ms\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "aks_service_name ='ro16n-aks-srvc01'\n",
    "\n",
    "from azureml.exceptions import WebserviceException\n",
    "try:\n",
    "    aks_service = Webservice.deploy_from_image(workspace = ws, \n",
    "                                               name = aks_service_name,\n",
    "                                               image = image_to_deploy,\n",
    "                                               deployment_config = aks_config,\n",
    "                                               deployment_target = aks_target)\n",
    "    aks_service.wait_for_deployment(show_output = True)\n",
    "    print(aks_service.state)\n",
    "except WebserviceException:\n",
    "    print('WebserviceException: There is already a service with name {} found in workspace {}. Will use it, and not create another one!'\\\n",
    "          .format(aks_service_name, ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ro16n-aks-srvc01\n",
      "r-svm-aci-service-01\n"
     ]
    }
   ],
   "source": [
    "# list all web services in the workspace\n",
    "for s in ws.webservices:\n",
    "    print(s)\n",
    "\n",
    "aks_service = Webservice(workspace = ws, name = aks_service_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "%dotenv $o16n_info_env_file_name\n",
    "dotenv_response = dotenv.set_key(o16n_info_env_file_name, 'aks_scoring_uri', aks_service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aks_service.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " data_size: 10 rows, jsoned data is 451 chars long\n",
      "              _row elapsed sys.self user.self\n",
      "0       all_r_time  230.00     4.00    196.00\n",
      "1  json_to_df_time    0.00     0.00      0.00\n",
      "233.41 ms all_p_time\n",
      "0.05 ms python_to_R_time\n",
      "0.02 ms R_to_python_time\n",
      "e2e_time :  347.62 ms\n",
      "service_time :  339.07 ms\n",
      "data_generation_time :  0.9 ms\n",
      "response_print_time :  7.66 ms\n",
      "rpy overhead summary \t \n",
      "r_processing time \t 230 ms\n",
      "python_processing time \t 233 ms\n",
      "rpy overhead \t 1.48 %\n",
      "\n",
      " data_size: 10 rows, jsoned data is 444 chars long\n",
      "              _row elapsed sys.self user.self\n",
      "0       all_r_time    4.00     0.00      5.00\n",
      "1  json_to_df_time    0.00     0.00      0.00\n",
      "6.98 ms all_p_time\n",
      "0.04 ms python_to_R_time\n",
      "0.02 ms R_to_python_time\n",
      "e2e_time :  71.84 ms\n",
      "service_time :  67.44 ms\n",
      "data_generation_time :  0.17 ms\n",
      "response_print_time :  4.22 ms\n",
      "rpy overhead summary \t \n",
      "r_processing time \t 4 ms\n",
      "python_processing time \t 7 ms\n",
      "rpy overhead \t 74.5 %\n",
      "\n",
      " data_size: 1000 rows, jsoned data is 43509 chars long\n",
      "              _row elapsed sys.self user.self\n",
      "0       all_r_time  177.00    12.00    199.00\n",
      "1  json_to_df_time   10.00     0.00     20.00\n",
      "181.97 ms all_p_time\n",
      "0.24 ms python_to_R_time\n",
      "0.03 ms R_to_python_time\n",
      "e2e_time :  357.18 ms\n",
      "service_time :  335.31 ms\n",
      "data_generation_time :  8.5 ms\n",
      "response_print_time :  13.36 ms\n",
      "rpy overhead summary \t \n",
      "r_processing time \t 177 ms\n",
      "python_processing time \t 182 ms\n",
      "rpy overhead \t 2.81 %\n",
      "\n",
      " data_size: 1000 rows, jsoned data is 43540 chars long\n",
      "              _row elapsed sys.self user.self\n",
      "0       all_r_time  140.00     0.00    188.00\n",
      "1  json_to_df_time   10.00     0.00     10.00\n",
      "143.53 ms all_p_time\n",
      "0.22 ms python_to_R_time\n",
      "0.02 ms R_to_python_time\n",
      "e2e_time :  351.23 ms\n",
      "service_time :  334.38 ms\n",
      "data_generation_time :  3.04 ms\n",
      "response_print_time :  13.81 ms\n",
      "rpy overhead summary \t \n",
      "r_processing time \t 140 ms\n",
      "python_processing time \t 144 ms\n",
      "rpy overhead \t 2.52 %\n",
      "\n",
      " data_size: 100000 rows, jsoned data is 4353549 chars long\n",
      "              _row   elapsed  sys.self user.self\n",
      "0       all_r_time  12349.00    101.00  12139.00\n",
      "1  json_to_df_time   1059.00     16.00   1044.00\n",
      "12446.37 ms all_p_time\n",
      "16.26 ms python_to_R_time\n",
      "0.31 ms R_to_python_time\n",
      "e2e_time :  16580.48 ms\n",
      "service_time :  15634.43 ms\n",
      "data_generation_time :  581.0 ms\n",
      "response_print_time :  365.05 ms\n",
      "rpy overhead summary \t \n",
      "r_processing time \t 12349 ms\n",
      "python_processing time \t 12446 ms\n",
      "rpy overhead \t 0.79 %\n",
      "\n",
      " data_size: 100000 rows, jsoned data is 4353888 chars long\n",
      "              _row   elapsed  sys.self user.self\n",
      "0       all_r_time  12517.00     25.00  12485.00\n",
      "1  json_to_df_time    997.00     16.00    982.00\n",
      "12607.88 ms all_p_time\n",
      "15.54 ms python_to_R_time\n",
      "0.51 ms R_to_python_time\n",
      "e2e_time :  16893.78 ms\n",
      "service_time :  15949.82 ms\n",
      "data_generation_time :  588.51 ms\n",
      "response_print_time :  355.46 ms\n",
      "rpy overhead summary \t \n",
      "r_processing time \t 12517 ms\n",
      "python_processing time \t 12608 ms\n",
      "rpy overhead \t 0.73 %\n"
     ]
    }
   ],
   "source": [
    "time_test_data_sizes = (1e1, 1e1, 1e3, 1e3, 1e5, 1e5)\n",
    "for time_test_data_size in time_test_data_sizes:\n",
    "    test_service(int(time_test_data_size), aci_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " data_size: 10 rows, jsoned data is 439 chars long\n",
      "              _row elapsed sys.self user.self\n",
      "0       all_r_time   15.00     0.00     22.00\n",
      "1  json_to_df_time    1.00     0.00      1.00\n",
      "88.01 ms all_p_time\n",
      "0.05 ms python_to_R_time\n",
      "0.06 ms R_to_python_time\n",
      "e2e_time :  402.42 ms\n",
      "service_time :  396.61 ms\n",
      "data_generation_time :  0.22 ms\n",
      "response_print_time :  5.59 ms\n",
      "rpy overhead summary \t \n",
      "r_processing time \t 15 ms\n",
      "python_processing time \t 88 ms\n",
      "rpy overhead \t 486.73 %\n",
      "\n",
      " data_size: 10 rows, jsoned data is 452 chars long\n",
      "              _row elapsed sys.self user.self\n",
      "0       all_r_time  236.00     0.00    236.00\n",
      "1  json_to_df_time    0.00     0.00      0.00\n",
      "239.54 ms all_p_time\n",
      "0.05 ms python_to_R_time\n",
      "0.02 ms R_to_python_time\n",
      "e2e_time :  534.75 ms\n",
      "service_time :  522.4 ms\n",
      "data_generation_time :  0.24 ms\n",
      "response_print_time :  12.1 ms\n",
      "rpy overhead summary \t \n",
      "r_processing time \t 236 ms\n",
      "python_processing time \t 240 ms\n",
      "rpy overhead \t 1.5 %\n",
      "\n",
      " data_size: 1000 rows, jsoned data is 43570 chars long\n",
      "              _row elapsed sys.self user.self\n",
      "0       all_r_time  110.00    27.00    361.00\n",
      "1  json_to_df_time   12.00     0.00     11.00\n",
      "114.05 ms all_p_time\n",
      "0.19 ms python_to_R_time\n",
      "0.02 ms R_to_python_time\n",
      "e2e_time :  518.51 ms\n",
      "service_time :  498.25 ms\n",
      "data_generation_time :  8.08 ms\n",
      "response_print_time :  12.18 ms\n",
      "rpy overhead summary \t \n",
      "r_processing time \t 110 ms\n",
      "python_processing time \t 114 ms\n",
      "rpy overhead \t 3.68 %\n",
      "\n",
      " data_size: 1000 rows, jsoned data is 43532 chars long\n",
      "              _row elapsed sys.self user.self\n",
      "0       all_r_time  109.00     0.00    385.00\n",
      "1  json_to_df_time   11.00     0.00     11.00\n",
      "114.24 ms all_p_time\n",
      "0.27 ms python_to_R_time\n",
      "0.03 ms R_to_python_time\n",
      "e2e_time :  501.21 ms\n",
      "service_time :  483.91 ms\n",
      "data_generation_time :  3.15 ms\n",
      "response_print_time :  14.16 ms\n",
      "rpy overhead summary \t \n",
      "r_processing time \t 109 ms\n",
      "python_processing time \t 114 ms\n",
      "rpy overhead \t 4.81 %\n",
      "\n",
      " data_size: 100000 rows, jsoned data is 4353441 chars long\n",
      "              _row   elapsed  sys.self user.self\n",
      "0       all_r_time  10742.00     29.00  17712.00\n",
      "1  json_to_df_time   1138.00      9.00   1128.00\n",
      "10850.06 ms all_p_time\n",
      "16.1 ms python_to_R_time\n",
      "0.34 ms R_to_python_time\n",
      "e2e_time :  14849.1 ms\n",
      "service_time :  13932.77 ms\n",
      "data_generation_time :  551.69 ms\n",
      "response_print_time :  364.64 ms\n",
      "rpy overhead summary \t \n",
      "r_processing time \t 10742 ms\n",
      "python_processing time \t 10850 ms\n",
      "rpy overhead \t 1.01 %\n",
      "\n",
      " data_size: 100000 rows, jsoned data is 4353839 chars long\n",
      "              _row   elapsed  sys.self user.self\n",
      "0       all_r_time  10945.00     68.00  18456.00\n",
      "1  json_to_df_time   1092.00     12.00   1080.00\n",
      "11057.47 ms all_p_time\n",
      "16.76 ms python_to_R_time\n",
      "1.28 ms R_to_python_time\n",
      "e2e_time :  14857.06 ms\n",
      "service_time :  13930.85 ms\n",
      "data_generation_time :  602.47 ms\n",
      "response_print_time :  323.74 ms\n",
      "rpy overhead summary \t \n",
      "r_processing time \t 10945 ms\n",
      "python_processing time \t 11057 ms\n",
      "rpy overhead \t 1.03 %\n"
     ]
    }
   ],
   "source": [
    "for time_test_data_size in time_test_data_sizes:\n",
    "    test_service(int(time_test_data_size), aks_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Clean-up\n",
    "# aci_service.delete()\n",
    "# aks_service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 020_RegularR_RealTime_deploi_ACI_AKS.ipynb to html\n",
      "[NbConvertApp] Writing 354700 bytes to 020_RegularR_RealTime_deploi_ACI_AKS.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html  020_RegularR_RealTime_deploi_ACI_AKS.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
